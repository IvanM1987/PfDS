{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 100\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = 'F:\\\\PfDS\\\\train.csv'\n",
    "data_base = pd.read_csv(excel_file)\n",
    "data_base.reset_index();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base.loc[data_base.HouseYear == 4968, 'HouseYear'] = 1968\n",
    "\n",
    "data_base.loc[data_base.HouseYear == 20052011, 'HouseYear'] = 2008\n",
    "\n",
    "data_base.loc[data_base.Id == 5927, 'Rooms'] = 2\n",
    "\n",
    "data_base.loc[data_base.Id == 8491, 'Rooms'] = 1\n",
    "\n",
    "data_base.loc[data_base.Id == 14003, 'Rooms'] = 2\n",
    "\n",
    "data_base.loc[data_base.Id == 14865, 'Rooms'] = 2\n",
    "\n",
    "data_base.loc[data_base.Id == 4282, 'Rooms'] = 4\n",
    "\n",
    "data_base.loc[data_base.Id == 6358, 'Rooms'] = 1\n",
    "\n",
    "data_base.loc[data_base.Id == 7594, 'Rooms'] = 1\n",
    "\n",
    "data_base.loc[data_base.Id == 238, 'Rooms'] = 4\n",
    "\n",
    "data_base.loc[data_base.Id == 4214, 'Rooms'] = 1\n",
    "\n",
    "data_base.loc[(data_base.Square < 25) & (data_base.Rooms == 1), ['Square', 'LifeSquare', 'KitchenSquare']] = [41.35, 9.76, 25.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = data_base.drop('Healthcare_1', axis = 1)\n",
    "\n",
    "data_base = data_base.drop(data_base[data_base.Rooms == 0].index)\n",
    "\n",
    "data_base = data_base.drop(data_base[data_base.Square < 20].index)\n",
    "\n",
    "data_base = data_base.drop(data_base[data_base.Square > 300].index)\n",
    "\n",
    "data_base = data_base.drop(data_base[data_base.Id == 16772].index)\n",
    "\n",
    "data_base = data_base.drop(data_base[data_base.Id == 13772].index)\n",
    "\n",
    "data_base = data_base.drop(data_base[data_base.Id == 3052].index)\n",
    "\n",
    "data_base = data_base.drop(data_base[(data_base.Price > 500000) & (data_base.Square < 85) & (data_base.Rooms < 3)].index)\n",
    "\n",
    "data_base.KitchenSquare.replace([0, 1, 2], np.NaN, inplace= True)\n",
    "\n",
    "mean_price = data_base.groupby('Rooms', as_index = False)[['Price']].mean().rename(columns = {'Price': 'mean_price'})\n",
    "\n",
    "mean_square = data_base.groupby('Rooms', as_index = False)[['Square']].mean().rename(columns={'Square':'mean_square'})\n",
    "\n",
    "kitchen_square_mean = data_base.groupby('Rooms', as_index = False)[['KitchenSquare']].mean().rename(columns = {'KitchenSquare':'meanKitchenSquare'})\n",
    "\n",
    "life_square_mean = data_base.groupby('Rooms', as_index = False)[['LifeSquare']].mean().rename(columns = {'LifeSquare':'meanLifeSquare'})\n",
    "\n",
    "mean_data = pd.merge(mean_price, mean_square, on = 'Rooms')\n",
    "\n",
    "mean_data = pd.merge(mean_data, kitchen_square_mean, on = 'Rooms')\n",
    "\n",
    "mean_data = pd.merge(mean_data, life_square_mean, on = 'Rooms')\n",
    "\n",
    "mean_data.mean_price = mean_data.mean_price.astype(int)\n",
    "\n",
    "data_base = pd.merge(data_base, mean_data, on = 'Rooms',  how = 'left')\n",
    "\n",
    "data_base.Ecology_3 = (data_base.Ecology_3 == 'A').astype(int)\n",
    "\n",
    "data_base.Ecology_2 = (data_base.Ecology_2 == 'A').astype(int)\n",
    "\n",
    "data_base.Shops_2 = (data_base.Shops_2 == 'A').astype(int)\n",
    "\n",
    "data_base.KitchenSquare = data_base.KitchenSquare.combine_first(data_base.meanKitchenSquare)\n",
    "\n",
    "Id_Kitchen = data_base.loc[data_base.Square < data_base.KitchenSquare, ['Id','Price', 'Rooms', 'Square']]\n",
    "\n",
    "data_base.loc[data_base.Id.isin(Id_Kitchen.Id), 'KitchenSquare'] = data_base.meanKitchenSquare\n",
    "\n",
    "data_base.LifeSquare = data_base.LifeSquare.combine_first(data_base.meanLifeSquare)\n",
    "\n",
    "data_base.loc[data_base.Id.isin(data_base.loc[data_base.Square < data_base.LifeSquare, 'Id']), 'LifeSquare'] = data_base.meanLifeSquare\n",
    "\n",
    "big_square_id = data_base.loc[(data_base['Rooms'] == 5) & (data_base['Square'] < 100), 'Id']\n",
    "\n",
    "data_base.loc[data_base.Square < data_base.LifeSquare, 'LifeSquare'] = data_base.Square - data_base.KitchenSquare \n",
    "\n",
    "data_base.loc[data_base.KitchenSquare > 25, 'KitchenSquare'] = data_base.meanKitchenSquare\n",
    "\n",
    "data_base.loc[data_base.HouseFloor < 1, 'HouseFloor'] = data_base['Floor']\n",
    "\n",
    "data_base.loc[data_base.HouseFloor > 50, 'HouseFloor'] = data_base.Floor\n",
    "\n",
    "floors = data_base.loc[data_base.HouseFloor > 3, ['HouseFloor', 'HouseYear']]\n",
    "\n",
    "mean_House_Floor = floors.groupby('HouseYear', as_index = False)['HouseFloor'].mean().rename(columns = {'HouseFloor':'mean_House_Floor'})\n",
    "\n",
    "mean_House_Floor = mean_House_Floor.astype(int)\n",
    "\n",
    "data_base = pd.merge(data_base, mean_House_Floor, on = 'HouseYear', how = 'left')\n",
    "\n",
    "data_base.loc[data_base.Floor > data_base.HouseFloor, 'HouseFloor'] = data_base.mean_House_Floor\n",
    "\n",
    "data_base.loc[data_base.Floor > data_base.HouseFloor, 'HouseFloor'] = data_base.Floor\n",
    "\n",
    "data_base.loc[data_base.LifeSquare < data_base.KitchenSquare, 'LifeSquare'] = data_base.Square - data_base.KitchenSquare\n",
    "\n",
    "data_stat1 = data_base.groupby(['DistrictId', 'Rooms'], as_index=False)[['Price']].mean().rename(columns={'Price': 'district_mean_price'})\n",
    "\n",
    "data_base = pd.merge(data_base, data_stat1, on=['DistrictId', 'Rooms'], how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file2 = 'F:\\\\PfDS\\\\test.csv'\n",
    "data = pd.read_csv(excel_file2)\n",
    "data.reset_index();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.Square < 25) & (data.Rooms == 1), ['Square', 'LifeSquare', 'KitchenSquare']] = [41.35, 9.76, 25.10]\n",
    "data = data.drop('Healthcare_1', axis = 1)\n",
    "data.loc[data.HouseYear > 2018, 'HouseYear'] = 2018\n",
    "data.loc[data.Id == 14498, 'Rooms'] = 4\n",
    "data.loc[data.Id == 14498, 'KitchenSquare'] = 14\n",
    "data.loc[data.Id == 14498, 'LifeSquare'] = 149\n",
    "data.loc[data.Id == 14498, 'HouseFloor'] = 10\n",
    "data.loc[data.Id == 170, 'Square'] = 63\n",
    "data.loc[data.Id == 11470, 'Rooms'] = 1\n",
    "data.loc[data.Id == 1435, 'Rooms'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.KitchenSquare.replace([0, 1, 2], np.NaN, inplace= True)\n",
    "\n",
    "mean_square = data.groupby('Rooms', as_index = False)[['Square']].mean().rename(columns={'Square':'mean_square'})\n",
    "\n",
    "kitchen_square_mean = data.groupby('Rooms', as_index = False)[['KitchenSquare']].mean().rename(columns = {'KitchenSquare':'meanKitchenSquare'})\n",
    "\n",
    "life_square_mean = data.groupby('Rooms', as_index = False)[['LifeSquare']].mean().rename(columns = {'LifeSquare':'meanLifeSquare'})\n",
    "\n",
    "mean_data2 = pd.merge(kitchen_square_mean, mean_square, on = 'Rooms')\n",
    "\n",
    "mean_data2 = pd.merge(mean_data2, life_square_mean, on = 'Rooms')\n",
    "\n",
    "data = pd.merge(data, mean_data2, on = 'Rooms',  how = 'left')\n",
    "\n",
    "data.Ecology_3 = (data.Ecology_3 == 'A').astype(int)\n",
    "\n",
    "data.Ecology_2 = (data.Ecology_2 == 'A').astype(int)\n",
    "\n",
    "data.Shops_2 = (data.Shops_2 == 'A').astype(int)\n",
    "\n",
    "data.KitchenSquare = data.KitchenSquare.combine_first(data.meanKitchenSquare)\n",
    "\n",
    "Id_Kitchen = data.loc[data.Square < data.KitchenSquare, 'Id']\n",
    "\n",
    "data.loc[data.Id.isin(Id_Kitchen), 'KitchenSquare'] = data.meanKitchenSquare\n",
    "\n",
    "data.LifeSquare = data.LifeSquare.combine_first(data.meanLifeSquare)\n",
    "\n",
    "data.loc[data.Id.isin(data.loc[data.Square < data.LifeSquare, 'Id']), 'LifeSquare'] = data.meanLifeSquare\n",
    "\n",
    "big_square_id = data.loc[(data['Rooms'] == 5) & (data['Square'] < 100), 'Id']\n",
    "\n",
    "data.loc[data.Square < data.LifeSquare, 'LifeSquare'] = data.Square - data.KitchenSquare \n",
    "\n",
    "data.loc[data.KitchenSquare > 25, 'KitchenSquare'] = data.meanKitchenSquare\n",
    "\n",
    "data.loc[data.HouseFloor < 1, 'HouseFloor'] = data['Floor']\n",
    "\n",
    "data.loc[data.HouseFloor > 50, 'HouseFloor'] = data.Floor\n",
    "\n",
    "floors = data.loc[data.HouseFloor > 3, ['HouseFloor', 'HouseYear']]\n",
    "\n",
    "mean_House_Floor = floors.groupby('HouseYear', as_index = False)['HouseFloor'].mean().rename(columns = {'HouseFloor':'mean_House_Floor'})\n",
    "\n",
    "mean_House_Floor = mean_House_Floor.astype(int)\n",
    "\n",
    "data = pd.merge(data, mean_House_Floor, on = 'HouseYear', how = 'left')\n",
    "\n",
    "data.loc[data.Floor > data.HouseFloor, 'HouseFloor'] = data.mean_House_Floor\n",
    "\n",
    "data.loc[data.Floor > data.HouseFloor, 'HouseFloor'] = data.Floor\n",
    "\n",
    "data.loc[data.LifeSquare < data.KitchenSquare, 'LifeSquare'] = data.Square - data.KitchenSquare\n",
    "\n",
    "data = pd.merge(data, data_stat1, on=['DistrictId', 'Rooms'], how='left')\n",
    "data = pd.merge(data, mean_price, on = 'Rooms', how='left')\n",
    "\n",
    "data.loc[data.district_mean_price.isna(), 'district_mean_price'] = data.Square * (data_base.Price / data_base.Square).mean() \n",
    "\n",
    "data.loc[data.mean_price.isna(), 'mean_price'] = data.Square * (data_base.Price / data_base.Square).mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_base.drop(columns = 'Price')\n",
    "y = data_base['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'n_estimators': np.arange(20, 30), \n",
    "'max_features': np.arange(15, 20),\n",
    "'max_depth': np.arange(5, 9)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=RandomForestRegressor(random_state=100),\n",
    "                  param_grid=parameters,\n",
    "                  scoring='r2',\n",
    "                  cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=100, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'n_estimators': array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]), 'max_features': array([15, 16, 17, 18, 19]), 'max_depth': array([5, 6, 7, 8])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'max_features': 15, 'n_estimators': 28}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(max_depth = 8, max_features = 15, n_estimators = 28, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=8,\n",
       "           max_features=15, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=28, n_jobs=None, oob_score=False, random_state=100,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7617553173027127"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(y_test, data_base_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = clf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = pd.DataFrame(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final_pred.join(data.Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.rename(columns={0:'Price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[['Id', 'Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[:, ['Id', 'Price']].to_csv('Margulis_predictions.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
